"""
ìŠ¤í¬ë¦½íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ (Pipeline 2)

ì •ë³´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì´ ìƒì„±í•œ Markdown íŒŒì¼ì„ ì½ì–´ 1ë¶„ ë‚´ì™¸ì˜ ì˜¤ë””ì˜¤ ê°€ì´ë“œ
ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ê³  outputs/script/ì— ì €ì¥í•œë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- /outputs/info/[keyword].md íŒŒì¼ ì½ê¸°
- ë²„ì „ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì§€ì› (prompts/script_generation/)
- OpenAI GPTë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ê°€ì´ë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
- /outputs/script/[keyword]_script.mdì— êµ¬ì¡°í™”ëœ ê²°ê³¼ ì €ì¥
"""

import os
import sys
import logging
from pathlib import Path
from typing import Optional
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€ (utils ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•´)
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.utils.prompt_loader import load_prompt, list_prompts
from src.utils.path_sanitizer import info_markdown_path, script_markdown_path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def _generate_dry_run_script(keyword: str, prompt_version: str) -> str:
    """
    dry_run ëª¨ë“œì—ì„œ ì‚¬ìš©í•  ê³ ì • í…œí”Œë¦¿ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

    Args:
        keyword: ìœ ë¬¼/ì¥ì†Œ í‚¤ì›Œë“œ
        prompt_version: í”„ë¡¬í”„íŠ¸ ë²„ì „

    Returns:
        í…ŒìŠ¤íŠ¸ìš© ìŠ¤í¬ë¦½íŠ¸ ë¬¸ìì—´
    """
    script = f"""# {keyword} ì˜¤ë””ì˜¤ ê°€ì´ë“œ

## ì¸ì‚¬ ë° ì†Œê°œ

ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ì€ {keyword}ì— ëŒ€í•´ í•¨ê»˜ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ë³¸ë¬¸

### ì—­ì‚¬ì  ë°°ê²½

(ë”°ëœ»í•˜ê²Œ) ì´ ìœ ë¬¼ì€ ìš°ë¦¬ë‚˜ë¼ì˜ ì°¬ë€í•œ ë¬¸í™”ìœ ì‚° ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.
ì˜¤ëœ ì„¸ì›” ë™ì•ˆ ë§ì€ ì´ì•¼ê¸°ë¥¼ í’ˆê³  ìˆìŠµë‹ˆë‹¤.

### ì‹œê°ì  íŠ¹ì§•

(ì²œì²œíˆ) ëˆˆìœ¼ë¡œ ì§ì ‘ ë³´ë©´, ê·¸ ì•„ë¦„ë‹¤ì›€ê³¼ ì •êµí•¨ì— ê°íƒ„í•˜ê²Œ ë©ë‹ˆë‹¤.
ì„¸ë°€í•œ ë¬¸ì–‘ê³¼ ìƒ‰ê°ì´ ì¡°í™”ë¥¼ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤.

### ë¬¸í™”ì  ì˜ë¯¸

ì´ ìœ ë¬¼ì€ ë‹¨ìˆœí•œ ë¬¼ê±´ì´ ì•„ë‹ˆë¼, ë‹¹ì‹œ ì‚¬ëŒë“¤ì˜ ì‚¶ê³¼ ì •ì‹ ì´ ë‹´ê¸´
ì†Œì¤‘í•œ ì—­ì‚¬ì˜ ì¦ê±°ì…ë‹ˆë‹¤.

## ë§ˆë¬´ë¦¬

(ë¶€ë“œëŸ½ê²Œ) ì˜¤ëŠ˜ ê°ìƒí•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.
ì´ ìœ ë¬¼ì´ ì—¬ëŸ¬ë¶„ì—ê²Œ íŠ¹ë³„í•œ ì˜ê°ì„ ì£¼ì—ˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤.

---
*[DRY RUN ëª¨ë“œë¡œ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ - í”„ë¡¬í”„íŠ¸ ë²„ì „: {prompt_version}]*
"""
    return script


def run(
    keyword: str,
    *,
    info_dir: Optional[Path] = None,
    output_dir: Optional[Path] = None,
    prompt_version: str = "v1",
    dry_run: bool = False,
    temperature: float = 0.7,
    model: str = "gpt-4o-mini"
) -> Path:
    """
    ìŠ¤í¬ë¦½íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Args:
        keyword: ìœ ë¬¼/ì¥ì†Œ í‚¤ì›Œë“œ (ì˜ˆ: "ì²­ì ìƒê°ìš´í•™ë¬¸ ë§¤ë³‘")
        info_dir: ì •ë³´ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: outputs/info)
        output_dir: ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸: outputs/script)
        prompt_version: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë²„ì „ (ê¸°ë³¸: "v1")
        dry_run: Trueì´ë©´ API í˜¸ì¶œ ì—†ì´ ê³ ì • í…œí”Œë¦¿ ìƒì„±
        temperature: LLM temperature íŒŒë¼ë¯¸í„° (0.0~1.0)
        model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª…

    Returns:
        ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ê²½ë¡œ (Path ê°ì²´)

    Raises:
        FileNotFoundError: ì •ë³´ íŒŒì¼ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ
        ValueError: API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ë•Œ (dry_run=Falseì¸ ê²½ìš°)
        Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ë“± ê¸°íƒ€ ì˜¤ë¥˜
    """
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    if info_dir is None:
        info_dir = Path("outputs/info")
    if output_dir is None:
        output_dir = Path("outputs/script")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)

    # íŒŒì¼ ê²½ë¡œ ìƒì„± (path_sanitizer í—¬í¼ ì‚¬ìš©)
    info_file = info_markdown_path(keyword, info_dir)
    output_file = script_markdown_path(keyword, output_dir)

    logger.info(f"ìŠ¤í¬ë¦½íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘: {keyword}")
    logger.info(f"í”„ë¡¬í”„íŠ¸ ë²„ì „: {prompt_version}")
    logger.info(f"ì…ë ¥ íŒŒì¼: {info_file}")
    logger.info(f"ì¶œë ¥ íŒŒì¼: {output_file}")

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
    try:
        prompt_template = load_prompt(prompt_version)
        logger.info(f"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì™„ë£Œ: {prompt_template.name}")
    except FileNotFoundError as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì‹¤íŒ¨: {e}")
        available = list_prompts()
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë²„ì „: {', '.join(available)}")
        raise

    # dry_run ëª¨ë“œ ì²˜ë¦¬
    if dry_run:
        logger.info("DRY RUN ëª¨ë“œ: ê³ ì • í…œí”Œë¦¿ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")
        script_content = _generate_dry_run_script(keyword, prompt_version)

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(script_content)

        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ: {output_file}")
        return output_file

    # ì •ë³´ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not info_file.exists():
        error_msg = f"ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {info_file}"
        logger.error(error_msg)
        raise FileNotFoundError(error_msg)

    # ì •ë³´ íŒŒì¼ ì½ê¸°
    logger.info("ì •ë³´ íŒŒì¼ ì½ê¸° ì¤‘...")
    with open(info_file, "r", encoding="utf-8") as f:
        info_content = f.read()

    logger.info(f"ì •ë³´ íŒŒì¼ ë¡œë“œ ì™„ë£Œ (ê¸¸ì´: {len(info_content)} ë¬¸ì)")

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        error_msg = "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        logger.error(error_msg)
        raise ValueError(error_msg)

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    user_prompt = prompt_template.format_user_prompt(info_content=info_content)

    # LLM í˜¸ì¶œ
    try:
        logger.info(f"LLM í˜¸ì¶œ ì‹œì‘ (ëª¨ë¸: {model}, temperature: {temperature})")

        from openai import OpenAI
        client = OpenAI(api_key=api_key)

        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": prompt_template.system_prompt
                },
                {
                    "role": "user",
                    "content": user_prompt
                }
            ],
            temperature=temperature
        )

        script_content = response.choices[0].message.content
        logger.info(f"LLM ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(script_content)} ë¬¸ì)")

    except Exception as e:
        error_msg = f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        raise Exception(error_msg) from e

    # ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(script_content)
        logger.info(f"âœ… ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")

    except Exception as e:
        error_msg = f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        raise Exception(error_msg) from e

    return output_file


def main():
    """CLI ì§„ì…ì """
    import argparse

    parser = argparse.ArgumentParser(
        description="ì˜¤ë””ì˜¤ ê°€ì´ë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš© (v1 í”„ë¡¬í”„íŠ¸, dry-run)
  python src/pipelines/script_gen.py --keyword "ì²­ì ìƒê°ìš´í•™ë¬¸ ë§¤ë³‘" --dry-run

  # v2 í”„ë¡¬í”„íŠ¸ë¡œ ì‹¤ì œ ìƒì„±
  python src/pipelines/script_gen.py --keyword "ì²­ì ìƒê°ìš´í•™ë¬¸ ë§¤ë³‘" --prompt-version v2

  # ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ë²„ì „ í™•ì¸
  python src/pipelines/script_gen.py --list-prompts
        """
    )
    parser.add_argument(
        "--keyword",
        type=str,
        help="ìœ ë¬¼/ì¥ì†Œ í‚¤ì›Œë“œ (ì˜ˆ: 'ì²­ì ìƒê°ìš´í•™ë¬¸ ë§¤ë³‘')"
    )
    parser.add_argument(
        "--info-dir",
        type=Path,
        default=None,
        help="ì •ë³´ íŒŒì¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: outputs/info)"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=None,
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: outputs/script)"
    )
    parser.add_argument(
        "--prompt-version",
        type=str,
        default="v1",
        help="í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë²„ì „ (ê¸°ë³¸: v1)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="í…ŒìŠ¤íŠ¸ ëª¨ë“œ (API í˜¸ì¶œ ì—†ì´ ê³ ì • í…œí”Œë¦¿ ìƒì„±)"
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=0.7,
        help="LLM temperature (0.0~1.0, ê¸°ë³¸: 0.7)"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-4o-mini",
        help="OpenAI ëª¨ë¸ëª… (ê¸°ë³¸: gpt-4o-mini)"
    )
    parser.add_argument(
        "--list-prompts",
        action="store_true",
        help="ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ë²„ì „ ëª©ë¡ ì¶œë ¥"
    )

    args = parser.parse_args()

    # í”„ë¡¬í”„íŠ¸ ëª©ë¡ ì¶œë ¥ ëª¨ë“œ
    if args.list_prompts:
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ë²„ì „:")
        print("="*60)
        for version in list_prompts():
            try:
                template = load_prompt(version)
                print(f"\n{version}:")
                print(f"  ì´ë¦„: {template.name}")
                print(f"  ì„¤ëª…: {template.description}")
                print(f"  íƒœê·¸: {', '.join(template.tags)}")
            except Exception as e:
                print(f"\n{version}: (ë¡œë“œ ì‹¤íŒ¨ - {e})")
        print("="*60)
        return

    # keyword í•„ìˆ˜ ì²´í¬
    if not args.keyword:
        parser.error("--keyword ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤ (ë˜ëŠ” --list-prompts ì‚¬ìš©)")

    try:
        output_path = run(
            keyword=args.keyword,
            info_dir=args.info_dir,
            output_dir=args.output_dir,
            prompt_version=args.prompt_version,
            dry_run=args.dry_run,
            temperature=args.temperature,
            model=args.model
        )

        print("\n" + "="*60)
        print("âœ… ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ!")
        print("="*60)
        print(f"í‚¤ì›Œë“œ: {args.keyword}")
        print(f"í”„ë¡¬í”„íŠ¸ ë²„ì „: {args.prompt_version}")
        print(f"ì¶œë ¥ íŒŒì¼: {output_path}")
        print(f"ëª¨ë“œ: {'DRY RUN (í…ŒìŠ¤íŠ¸)' if args.dry_run else 'ì‹¤ì œ ìƒì„±'}")
        print("="*60)

        # ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì)
        with open(output_path, "r", encoding="utf-8") as f:
            content = f.read()
            preview = content[:200]

        print("\nğŸ“„ ìŠ¤í¬ë¦½íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
        print("-"*60)
        print(preview + "..." if len(content) > 200 else preview)
        print("-"*60)

    except FileNotFoundError as e:
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        sys.exit(1)
    except ValueError as e:
        logger.error(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
