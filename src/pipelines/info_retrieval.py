"""
ì •ë³´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ (Pipeline 1)

ì…ë ¥ëœ ë¬¸í™”ìœ ì‚° í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì„ í™œìš©í•´ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ ,
êµ¬ì¡°í™”ëœ Markdown íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- OpenAI GPT ëª¨ë¸ì„ í™œìš©í•œ ë¬¸í™”ìœ ì‚° ì •ë³´ ê²€ìƒ‰ ë° ìš”ì•½
- YAML ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ì§€ì› (ë²„ì „ë³„ ê´€ë¦¬ ê°€ëŠ¥)
- ì„œë¡ , ì—­ì‚¬/ë°°ê²½, íŠ¹ì§•, ì¶”ê°€ ì‚¬ì‹¤, ì°¸ê³  ë¬¸í—Œ ë“± êµ¬ì¡°í™”ëœ Markdown ìƒì„±
- outputs/info/ ë””ë ‰í† ë¦¬ì— íŒŒì¼ ì €ì¥
- ì—ëŸ¬ ì²˜ë¦¬ ë° dry_run ëª¨ë“œ ì§€ì›
"""

import logging
import os
from pathlib import Path
from typing import Optional

from dotenv import load_dotenv
from openai import OpenAI

from src.utils.path_sanitizer import info_markdown_path
from src.utils.metadata import create_metadata
from src.utils.prompt_loader import load_prompt, list_prompts

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# ê¸°ë³¸ ì„¤ì •
DEFAULT_OUTPUT_DIR = Path("outputs/info")
DEFAULT_MOCK_OUTPUT_DIR = Path("outputs/mock/info")
# [TODO] 4.1ì¶”ì²œ -> 
DEFAULT_MODEL = "gpt-4.1"


def _validate_api_key() -> str:
    """
    OpenAI API í‚¤ ìœ íš¨ì„± ê²€ì¦

    Returns:
        str: ìœ íš¨í•œ API í‚¤

    Raises:
        ValueError: API í‚¤ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆì„ ê²½ìš°
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError(
            "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            ".env íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
        )
    return api_key


def _search_with_llm(
    keyword: str,
    model: str = DEFAULT_MODEL,
    prompt_version: str = "default"
) -> str:
    """
    OpenAI LLMì„ í™œìš©í•´ ë¬¸í™”ìœ ì‚° ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•œë‹¤.

    Args:
        keyword: ê²€ìƒ‰í•  ë¬¸í™”ìœ ì‚° í‚¤ì›Œë“œ
        model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª…
        prompt_version: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë²„ì „ (ê¸°ë³¸ê°’: "default")

    Returns:
        str: LLMì´ ìƒì„±í•œ êµ¬ì¡°í™”ëœ ì •ë³´

    Raises:
        Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
    """
    api_key = _validate_api_key()
    client = OpenAI(api_key=api_key)

    # YAML í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
    try:
        prompt_template = load_prompt(
            version=prompt_version,
            pipeline_type="info_retrieval"
        )
        logger.info(f"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì™„ë£Œ: {prompt_template.name} (ë²„ì „: {prompt_version})")
        logger.info(f"í”„ë¡¬í”„íŠ¸ ì„¤ëª…: {prompt_template.description}")
        logger.info(f"API íƒ€ì…: {prompt_template.api_type}")
    except FileNotFoundError as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì‹¤íŒ¨: {e}")
        available = list_prompts(pipeline_type="info_retrieval")
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë²„ì „: {', '.join(available)}")
        raise

    logger.info(f"LLM ê²€ìƒ‰ ì‹œì‘: {keyword} (ëª¨ë¸: {model})")

    try:
        # Responses API ì‚¬ìš© (ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í¬í•¨)
        # YAML í…œí”Œë¦¿ì—ì„œ í”„ë¡¬í”„íŠ¸ì™€ tools ê°€ì ¸ì˜¤ê¸°
        response = client.responses.create(
            model=model,
            instructions=prompt_template.instructions,
            input=prompt_template.format_input(keyword=keyword),
            tools=prompt_template.tools
        )

        content = response.output_text
        logger.info(f"LLM ê²€ìƒ‰ ì™„ë£Œ: {len(content)} ê¸€ì")
        return content

    except Exception as e:
        logger.error(f"LLM ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise


def _get_mock_data(keyword: str) -> str:
    """
    dry_run ëª¨ë“œìš© ëª©ì—… ë°ì´í„° ìƒì„±

    Args:
        keyword: ë¬¸í™”ìœ ì‚° í‚¤ì›Œë“œ

    Returns:
        str: ëª©ì—… Markdown ë°ì´í„°
    """
    return f"""# {keyword}

## ê°œìš”
ì´ê²ƒì€ '{keyword}'ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ìš© ëª©ì—… ë°ì´í„°ì…ë‹ˆë‹¤.
ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹  ë°˜í™˜ë˜ëŠ” ìƒ˜í”Œ ë°ì´í„°ì…ë‹ˆë‹¤.

## ì—­ì‚¬ ë° ë°°ê²½
- **ì‹œëŒ€**: ê³ ë ¤ì‹œëŒ€ (12ì„¸ê¸°)
- **ì œì‘ ì‹œê¸°**: ì•½ 1150ë…„ê²½
- **ì—­ì‚¬ì  ì˜ë¯¸**: ê³ ë ¤ì²­ìì˜ ì „ì„±ê¸°ë¥¼ ëŒ€í‘œí•˜ëŠ” ì‘í’ˆ

## ì£¼ìš” íŠ¹ì§•
- **ì™¸í˜•**: ìš°ì•„í•œ ê³¡ì„ ê³¼ ë¹„ì·¨ìƒ‰ ìœ ì•½
- **ê¸°ìˆ **: ìƒê° ê¸°ë²•ì˜ ì •êµí•¨
- **ì˜ˆìˆ ì„±**: êµ¬ë¦„ê³¼ í•™ ë¬¸ì–‘ì˜ ì¡°í™”ë¡œìš´ ë°°ì¹˜

## ì¶”ê°€ ì •ë³´
- **ì†Œì¥ì²˜**: êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€
- **ì§€ì •**: êµ­ë³´ ì œ68í˜¸
- **íŠ¹ì´ì‚¬í•­**: ê³ ë ¤ì²­ì ì¤‘ ê°€ì¥ ì™„ì„±ë„ ë†’ì€ ì‘í’ˆìœ¼ë¡œ í‰ê°€

## ì°¸ê³  ìë£Œ
- êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ ì†Œì¥í’ˆ ë°ì´í„°ë² ì´ìŠ¤
- í•œêµ­ë¯¼ì¡±ë¬¸í™”ëŒ€ë°±ê³¼ì‚¬ì „
- ë¬¸í™”ì¬ì²­ êµ­ê°€ë¬¸í™”ìœ ì‚°í¬í„¸
"""


def run(
    keyword: str,
    *,
    output_dir: Optional[Path] = None,
    model: str = DEFAULT_MODEL,
    prompt_version: str = "default",
    dry_run: bool = False,
    output_name: Optional[str] = None
) -> Path:
    """
    ì •ë³´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    ì£¼ì–´ì§„ í‚¤ì›Œë“œì— ëŒ€í•œ ë¬¸í™”ìœ ì‚° ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ ,
    êµ¬ì¡°í™”ëœ Markdown íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.

    Args:
        keyword: ê²€ìƒ‰í•  ë¬¸í™”ìœ ì‚° í‚¤ì›Œë“œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: outputs/info)
        model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª… (ê¸°ë³¸ê°’: gpt-4.1)
        prompt_version: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë²„ì „ (ê¸°ë³¸ê°’: "default")
        dry_run: Trueì¼ ê²½ìš° API í˜¸ì¶œ ì—†ì´ ëª©ì—… ë°ì´í„° ì‚¬ìš©
        output_name: íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ì´ë¦„ (ì„ íƒì , ë¯¸ì œê³µ ì‹œ keyword ì‚¬ìš©)

    Returns:
        Path: ìƒì„±ëœ Markdown íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ

    Raises:
        ValueError: API í‚¤ê°€ ì—†ê±°ë‚˜ í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆì„ ê²½ìš°
        Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ë˜ëŠ” íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ ì‹œ

    Example:
        >>> from pathlib import Path
        >>> output_path = run("ì²­ì ìƒê°ìš´í•™ë¬¸ ë§¤ë³‘")
        >>> print(f"ì €ì¥ ì™„ë£Œ: {output_path}")
        >>> output_path = run("êµ­ë¦½ ì¤‘ì•™ ë°•ë¬¼ê´€ì— ìˆëŠ” ì‚¬ìœ ì˜ ë°©", output_name="ì‚¬ìœ ì˜ë°©")
        >>> print(f"ì €ì¥ ì™„ë£Œ: {output_path}")  # outputs/info/ì‚¬ìœ ì˜ë°©.md
    """
    # ì…ë ¥ ê²€ì¦
    if not keyword or not keyword.strip():
        raise ValueError("í‚¤ì›Œë“œëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    keyword = keyword.strip()
    mode = "dry_run" if dry_run else "production"
    logger.info(f"{'[DRY RUN] ' if dry_run else ''}ì •ë³´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {keyword}")
    logger.info(f"í”„ë¡¬í”„íŠ¸ ë²„ì „: {prompt_version}")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •: dry_run ëª¨ë“œì¼ ê²½ìš° outputs/mock/info/ ì‚¬ìš©
    if output_dir is None:
        output_dir = DEFAULT_MOCK_OUTPUT_DIR if dry_run else DEFAULT_OUTPUT_DIR

    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir.absolute()}")

    # ì •ë³´ ê²€ìƒ‰
    if dry_run:
        logger.info("DRY RUN ëª¨ë“œ: ëª©ì—… ë°ì´í„° ì‚¬ìš©")
        content = _get_mock_data(keyword)
    else:
        content = _search_with_llm(keyword, model=model, prompt_version=prompt_version)

    # íŒŒì¼ ê²½ë¡œ ìƒì„± (ê³µí†µ í—¬í¼ ì‚¬ìš©)
    output_path = info_markdown_path(keyword, output_dir, output_name)

    try:
        output_path.write_text(content, encoding="utf-8")
        logger.info(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path.absolute()}")
    except Exception as e:
        logger.error(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise

    # ë©”íƒ€ë°ì´í„° ìƒì„±
    try:
        create_metadata(
            keyword=keyword,
            pipeline="info_retrieval",
            output_file_path=output_path,
            mode=mode,
            model=model if not dry_run else None
        )
    except Exception as e:
        logger.warning(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ (íŒŒì´í”„ë¼ì¸ì€ ê³„ì† ì§„í–‰): {e}")

    return output_path.absolute()


def main():
    """
    CLI ì§„ì…ì 

    argparseë¥¼ ì‚¬ìš©í•´ ëª…ë ¹ì¤„ì—ì„œ í‚¤ì›Œë“œë¥¼ ì…ë ¥ë°›ì•„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•œë‹¤.

    Example:
        $ python -m src.pipelines.info_retrieval --keyword "ì²­ì ìƒê°ìš´í•™ë¬¸ ë§¤ë³‘"
        $ python -m src.pipelines.info_retrieval --keyword "ì„êµ´ì•”" --dry-run
        $ python -m src.pipelines.info_retrieval --list-prompts
    """
    import argparse

    parser = argparse.ArgumentParser(
        description="ë¬¸í™”ìœ ì‚° ì •ë³´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ (YAML í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì§€ì›)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ ì‚¬ìš©
  python -m src.pipelines.info_retrieval --keyword "ì²­ì ìƒê°ìš´í•™ë¬¸ ë§¤ë³‘"

  # í”„ë¡¬í”„íŠ¸ ë²„ì „ ì§€ì •
  python -m src.pipelines.info_retrieval --keyword "ì„êµ´ì•”" --prompt-version default

  # Dry-run ëª¨ë“œ
  python -m src.pipelines.info_retrieval --keyword "í›ˆë¯¼ì •ìŒ" --dry-run

  # ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ë²„ì „ í™•ì¸
  python -m src.pipelines.info_retrieval --list-prompts
        """
    )

    parser.add_argument(
        "--keyword",
        type=str,
        help="ê²€ìƒ‰í•  ë¬¸í™”ìœ ì‚° í‚¤ì›Œë“œ"
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help=f"ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: {DEFAULT_OUTPUT_DIR})"
    )

    parser.add_argument(
        "--model",
        type=str,
        default=DEFAULT_MODEL,
        help=f"ì‚¬ìš©í•  OpenAI ëª¨ë¸ (ê¸°ë³¸ê°’: {DEFAULT_MODEL})"
    )

    parser.add_argument(
        "--prompt-version",
        type=str,
        default="default",
        help="í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë²„ì „ (ê¸°ë³¸ê°’: default)"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="API í˜¸ì¶œ ì—†ì´ ëª©ì—… ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸"
    )

    parser.add_argument(
        "--output-name",
        type=str,
        default=None,
        help="íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ì´ë¦„ (ë¯¸ì œê³µ ì‹œ keyword ì‚¬ìš©)"
    )

    parser.add_argument(
        "--list-prompts",
        action="store_true",
        help="ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ë²„ì „ ëª©ë¡ ì¶œë ¥"
    )

    args = parser.parse_args()

    # í”„ë¡¬í”„íŠ¸ ëª©ë¡ ì¶œë ¥ ëª¨ë“œ
    if args.list_prompts:
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ë²„ì „:")
        print("="*70)
        for version in list_prompts(pipeline_type="info_retrieval"):
            try:
                template = load_prompt(version, pipeline_type="info_retrieval")
                print(f"\nğŸ“ {version}:")
                print(f"    ì´ë¦„: {template.name}")
                print(f"    ì„¤ëª…: {template.description}")
                print(f"    API íƒ€ì…: {template.api_type}")
                print(f"    íƒœê·¸: {', '.join(template.tags)}")
            except Exception as e:
                print(f"\nâŒ {version}: (ë¡œë“œ ì‹¤íŒ¨ - {e})")
        print("\n" + "="*70)
        print("\nğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:")
        print('  python -m src.pipelines.info_retrieval --keyword "ì²­ì ë§¤ë³‘" --prompt-version default')
        print("="*70)
        return

    # keyword í•„ìˆ˜ ì²´í¬
    if not args.keyword:
        parser.error("--keyword ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤ (ë˜ëŠ” --list-prompts ì‚¬ìš©)")

    try:
        output_path = run(
            keyword=args.keyword,
            output_dir=Path(args.output_dir) if args.output_dir else None,
            model=args.model,
            prompt_version=args.prompt_version,
            dry_run=args.dry_run,
            output_name=args.output_name
        )

        print(f"\nâœ… ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ!")
        print(f"ğŸ“„ íŒŒì¼ ìœ„ì¹˜: {output_path}")
        print(f"í”„ë¡¬í”„íŠ¸ ë²„ì „: {args.prompt_version}")
        print(f"\në‹¤ìŒ ë‹¨ê³„: ìƒì„±ëœ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        print(f"  cat {output_path}")

    except ValueError as e:
        print(f"âŒ ì…ë ¥ ì˜¤ë¥˜: {e}")
        exit(1)
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        logger.exception("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        exit(1)


if __name__ == "__main__":
    main()
